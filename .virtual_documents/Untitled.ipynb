


import os
import time
import random
import pandas as pd
import numpy as np
import cv2
import torch
from tqdm.auto import tqdm
from PIL import Image
import shutil
import matplotlib.pyplot as plt
%matplotlib inline





df = pd.read_csv('data/train_solution_bounding_boxes (1).csv')
df.head()


# get image_id
df['image_id'] = df['image'].apply(lambda x: x.split('.')[0])
df['classes'] = 0
df.head(10)


# initialize configuration
img_h, img_w, num_channels = (380, 676, 3)
images_folder = 'data/training_images/'


# convert the data points to YOLO format
df['x_center'] = (df['xmin'] + df['xmax']) / 2
df['y_center'] = (df['ymin'] + df['ymax']) / 2
df['w'] = df['xmax'] - df['xmin']
df['h'] = df['ymax'] - df['ymin']


# normalize the values
df['x_center'] = df['x_center'] / img_w
df['y_center'] = df['y_center'] / img_h
df['w'] = df['w'] / img_w
df['h'] = df['h'] / img_h


df.head(10)





image = random.choice(df['image'])
image_path = os.path.join(images_folder, image)
img = Image.open(image_path)
plt.axis('off')
plt.imshow(img)
plt.show()


image = random.choice(df['image'])
image_path = os.path.join(images_folder, image)
img = Image.open(image_path)
plt.axis('off')
plt.imshow(img)
plt.show()


def draw_bounding_box(idx):
    image = cv2.imread(os.path.join(images_folder, df['image'][idx]))
    x_min = int(df['xmin'][idx])
    y_min = int(df['ymin'][idx])
    x_max = int(df['xmax'][idx])
    y_max = int(df['ymax'][idx])

    # draw the rectangle
    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
    # place the label above bounding boxes
    cv2.putText(image, 'car', (x_min, y_min-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # display the image
    plt.axis('off')
    plt.imshow(image)
    plt.show()





idx = random.randrange(0, len(df))
draw_bounding_box(idx)





annotations_folder = 'data/annotations/'

if not os.path.exists(annotations_folder):
    os.mkdir(annotations_folder)


annotations_dict = {}

# iterate through dataframe to consolidate bounding boxes for each image
for _, row in df.iterrows():
    image_file = row['image']
    class_label = int(row['classes'])
    x_center = row['x_center']
    y_center = row['y_center']
    w = row['w']
    h = row['h']

    # initialize list if image is not present in dicitionary
    if image_file not in annotations_dict:
        annotations_dict[image_file] = []

    # append annotations to the list 
    annotations_dict[image_file].append(f"{class_label} {x_center} {y_center} {w} {h}")

# write the annotations in text file
for image_file, annotations in annotations_dict.items():
    annotation_file = os.path.join(annotations_folder, os.path.splitext(image_file)[0] + '.txt')
    with open(annotation_file, 'w') as f:
        for annotation in annotations:
            f.write(annotation + '\n')


# split images for training and testing
from sklearn.model_selection import train_test_split
images = list(annotations_dict.keys())
train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)


# create folders for train and test
train_images_folder = 'datasets/train_images'
test_images_folder = 'datasets/test_images'
train_annotations_folder = 'datasets/train_annotations'
test_annotations_folder = 'datasets/test_annotations'

# create directors for the above paths
os.mkdir('datasets')
os.mkdir(train_images_folder)
os.mkdir(test_images_folder)
os.mkdir(train_annotations_folder)
os.mkdir(test_annotations_folder)


# copy the files to the respective folder paths
def copy_files(images_list, image_src_folder, annotation_src_folder, image_dest_folder, annotation_dest_folder):
    for image_file in images_list:
        # path for source and destination
        src_image_path = os.path.join(image_src_folder, image_file)
        annotation_file = os.path.splitext(image_file)[0] + '.txt'
        src_annotations_path = os.path.join(annotation_src_folder, annotation_file)
        dest_image_path = os.path.join(image_dest_folder, image_file)
        dest_annotation_path = os.path.join(annotation_dest_folder, annotation_file)

        # copy images
        shutil.copy2(src_image_path,  dest_image_path)
        # copy annotations
        shutil.copy2(src_annotations_path, dest_annotation_path)


copy_files(train_images, images_folder, annotations_folder, train_images_folder, train_annotations_folder)
copy_files(test_images, images_folder, annotations_folder, test_images_folder, test_annotations_folder)





from ultralytics import YOLO
# load pretrained model
model = YOLO('yolov8n.yaml')

# define training parameters
model.train(data='data.yaml', epochs=50, batch=16, imgsz=676, workers=2)


ultralytics.utils.metrics.DetMetrics object with attributes:



metrics = model.val()



# # load the weights
# best_model = YOLO('yolov8n.yaml')
# best_model.load('runs/detect/train/weights/best.pt')





# process the results
image_path = 'datasets/test_images/vid_4_10020.jpg'
results = model(image_path)
image = cv2.imread(image_path)
for result in results:
    # loop through the detected objects
    for detection in result.boxes:
        x_min, y_min, x_max, y_max = detection.xyxy[0]
        confidence = round(float(detection.conf[0]), 2)
        class_id = int(detection.cls[0])

        # draw bouding box
        cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)

        # write label
        label = f"Car {confidence}"
        cv2.putText(image, label, (int(x_min), int(y_min)-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

# convert the image to rgb
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

plt.imshow(image_rgb)
plt.axis('off')
plt.show()



